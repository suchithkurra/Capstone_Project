{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.metrics import classification_report, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "# Replace 'veremi.csv' with the path to your dataset\n",
    "data = pd.read_csv('/Users/suchithkurra/Desktop/capstone /sampled_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming that the last column is the target variable and others are features\n",
    "X = data.iloc[:, :-1]  # Features\n",
    "y = data.iloc[:, -1]   # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Apply Label Encoding on the target variable\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 10 features: ['type', 'pos_0', 'pos_1', 'pos_noise_0', 'pos_noise_1', 'spd_0', 'spd_1', 'acl_0', 'acl_1', 'hed_noise_1']\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "selector = SelectKBest(score_func=f_classif, k=k)\n",
    "X_train_selected = selector.fit_transform(X_train, y_train)\n",
    "X_test_selected = selector.transform(X_test)\n",
    "\n",
    "# Get the selected feature indices and names\n",
    "selected_feature_indices = selector.get_support(indices=True)\n",
    "selected_features = X.columns[selected_feature_indices]\n",
    "\n",
    "# Print the selected features\n",
    "print(f'Selected {k} features: {selected_features.tolist()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# Create an SVM model and wrap it in the One-vs-Rest strategy\n",
    "svm = SVC(kernel='linear', probability=True)  # You can also try other kernels like 'rbf', 'poly', etc.\n",
    "ovr_classifier = OneVsRestClassifier(svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ovr_classifier.fit(X_train_selected, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = ovr_classifier.predict(X_test_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 6.75%\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          ConstPos       0.06      0.05      0.05       289\n",
      "    ConstPosOffset       0.05      0.00      0.01       314\n",
      "        ConstSpeed       0.00      0.00      0.00       277\n",
      "  ConstSpeedOffset       0.02      0.01      0.01       288\n",
      "        DataReplay       0.06      0.01      0.02       308\n",
      "   DataReplaySybil       0.00      0.00      0.00       330\n",
      "   DelayedMessages       0.05      0.08      0.07       319\n",
      "        Disruptive       0.00      0.00      0.00       307\n",
      "               DoS       0.08      0.05      0.06       343\n",
      "     DoSDisruptive       0.00      0.00      0.00       341\n",
      "DoSDisruptiveSybil       0.06      0.21      0.09       339\n",
      "         DoSRandom       0.09      0.52      0.15       340\n",
      "    DoSRandomSybil       0.04      0.09      0.05       293\n",
      "      EventualStop       0.00      0.00      0.00       311\n",
      "         GridSybil       0.09      0.14      0.11       358\n",
      "         RandomPos       0.05      0.04      0.04       323\n",
      "   RandomPosOffset       0.00      0.00      0.00       321\n",
      "       RandomSpeed       0.00      0.00      0.00       296\n",
      " RandomSpeedOffset       0.05      0.01      0.02       303\n",
      "\n",
      "          accuracy                           0.07      6000\n",
      "         macro avg       0.04      0.06      0.04      6000\n",
      "      weighted avg       0.04      0.07      0.04      6000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1497: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Detailed classification report\n",
    "print(classification_report(y_test, y_pred, target_names=le.classes_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
